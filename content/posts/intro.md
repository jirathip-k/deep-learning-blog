---
title: "Introduction to Deep Learning"
date: 2023-10-23T21:44:00+11:00
draft: false
---

# Deep Learning

The general idea for deep learning is to find model parameters that model prediction the training set as much as possible

## Generalisation

## Feed Forward

## Back Propagation

### Gradient Descent

Gradient is the first order derivative which can be used to indicate the directional of the steepest increase or decrease of a function. At its core, gradient descent is an optimization algorithm that's used to minimize some function by iteratively moving in the direction of steepest descent as defined by the negative of the gradient. This can be used to adjust the model parameters in such a way that loss is minimised.
